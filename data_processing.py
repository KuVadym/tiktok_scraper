import asyncio
import random
import json
from playwright.async_api import Page
from loguru import logger as log

from urllib.parse import quote
from browser import create_browser_with_session, create_browser_with_new_context
from ustils import save_posts_to_csv
import logging
from config import *
from scraping import scrap_necessary_data
from parsel import Selector


log = logging.getLogger(__name__)


async def check_captcha(page):
    """ ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ”, Ñ‡Ğ¸ Ñ” ĞºĞ°Ğ¿Ñ‡Ğ°, Ñ– Ñ‡ĞµĞºĞ°Ñ” Ñ—Ñ— Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¶ĞµĞ½Ğ½Ñ """
    while True:
        captcha_present = await page.query_selector('iframe[src*="captcha"]')  # Ğ—Ğ¼Ñ–Ğ½ÑĞ¹ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ½Ğ¾ Ğ´Ğ¾ ÑĞ°Ğ¹Ñ‚Ñƒ
        if captcha_present:
            print("ĞšĞ°Ğ¿Ñ‡Ğ° Ğ²Ğ¸ÑĞ²Ğ»ĞµĞ½Ğ°! ĞÑ‡Ñ–ĞºÑƒÑ”Ğ¼Ğ¾ Ñ—Ñ— Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¶ĞµĞ½Ğ½Ñ Ğ²Ñ€ÑƒÑ‡Ğ½Ñƒ...")
            await asyncio.sleep(5)  # Ğ§ĞµĞºĞ°Ñ”Ğ¼Ğ¾ ĞºÑ–Ğ»ÑŒĞºĞ° ÑĞµĞºÑƒĞ½Ğ´ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ñ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¾Ñ
        else:
            print("ĞšĞ°Ğ¿Ñ‡Ğ° Ğ·Ğ½Ğ¸ĞºĞ»Ğ°! ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ²Ğ¶ÑƒÑ”Ğ¼Ğ¾ Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ñƒ.")
            break


async def get_video_duration(page: Page) -> float:
    try:
        await page.wait_for_selector('video', timeout=10000)
        duration = await page.evaluate("document.querySelector('video')?.duration")
        duration += 2
        return duration or 0.0
    except Exception as e:
        log.warning(f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚Ğ¸ Ñ‚Ñ€Ğ¸Ğ²Ğ°Ğ»Ñ–ÑÑ‚ÑŒ Ğ²Ñ–Ğ´ĞµĞ¾: {e}")
        return 0.0
    

def should_execute_event(probability_percent: int) -> bool:
    return random.randint(1, 100) <= probability_percent


async def like_video(page: Page):
    print("ğŸŒŸ ĞŸĞ¾Ñ‡Ğ¸Ğ½Ğ°Ñ”Ğ¼Ğ¾ ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚Ğ¸ Ğ»Ğ°Ğ¹Ğº...")

    try:
        # Ğ§ĞµĞºĞ°Ñ”Ğ¼Ğ¾ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ğ»Ğ°Ğ¹ĞºÑƒ
        like_button = await page.wait_for_selector('[data-e2e="like-icon"]', timeout=5000)

        # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ”Ğ¼Ğ¾ Ğ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºĞ¾Ğ²Ğ¸Ğ¹ ÑÑ‚Ğ°Ğ½
        initial_state = await like_button.get_attribute("aria-pressed")
        print(f"ğŸ” ĞŸĞ¾Ñ‡Ğ°Ñ‚ĞºĞ¾Ğ²Ğ¸Ğ¹ ÑÑ‚Ğ°Ğ½ aria-pressed: {initial_state}")

        if initial_state == "true":
            print("âœ… Ğ’Ñ–Ğ´ĞµĞ¾ Ğ²Ğ¶Ğµ Ğ»Ğ°Ğ¹ĞºĞ½ÑƒÑ‚Ğ¾.")
            return

        # ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¸ Ğ´Ğ»Ñ Ñ–Ğ¼Ñ–Ñ‚Ğ°Ñ†Ñ–Ñ— Ğ»ÑĞ´ÑÑŒĞºĞ¾Ğ³Ğ¾ ĞºĞ»Ñ–ĞºÑƒ
        box = await like_button.bounding_box()
        if box:
            await page.mouse.move(box["x"] + box["width"] / 2, box["y"] + box["height"] / 2)
            await asyncio.sleep(0.2)
            await page.mouse.down()
            await asyncio.sleep(0.2)
            await page.mouse.up()
            print("ğŸ–±ï¸ Ğ’Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ¾ Ñ–Ğ¼Ñ–Ñ‚Ğ°Ñ†Ñ–Ñ Ğ»ÑĞ´ÑÑŒĞºĞ¾Ğ³Ğ¾ ĞºĞ»Ñ–ĞºÑƒ.")
        else:
            log.warning("âš ï¸ ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ñ‚Ğ¸ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¸ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ»Ğ°Ğ¹ĞºÑƒ.")
            return

        # Ğ—Ğ°Ñ‡ĞµĞºĞ°Ñ”Ğ¼Ğ¾, Ğ¿Ğ¾ĞºĞ¸ Ğ·Ğ¼Ñ–Ğ½Ğ¸Ñ‚ÑŒÑÑ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚
        await asyncio.sleep(2)
        after_state = await like_button.get_attribute("aria-pressed")
        print(f"ğŸ”„ ĞŸÑ–ÑĞ»Ñ ĞºĞ»Ñ–ĞºÑƒ: aria-pressed = {after_state}")

        if after_state == "true":
            print("âœ… Ğ›Ğ°Ğ¹Ğº Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾.")
        else:
            print("âš ï¸ Ğ›Ğ°Ğ¹Ğº Ğ½Ğµ Ğ·Ğ°Ñ„Ñ–ĞºÑĞ¾Ğ²Ğ°Ğ½Ğ¾ (ĞºĞ»Ğ°Ñ Ğ½Ğµ Ğ·Ğ¼Ñ–Ğ½Ğ¸Ğ²ÑÑ).")

    except Exception as e:
        log.warning(f"âŒ Ğ’Ğ¸Ğ½Ğ¸ĞºĞ»Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ»Ğ°Ğ¹ĞºĞ°Ğ½Ğ½Ñ–: {e}")

async def leave_comment(page: Page, comment_text: str):
    try:
        await page.wait_for_timeout(random.randint(500, 1000))

        await page.click('[data-e2e="comment-icon"]')
        await page.wait_for_selector('[data-e2e="comment-input"] [contenteditable="true"]', timeout=7000)

        comment_box = await page.query_selector('[data-e2e="comment-input"] [contenteditable="true"]')
        if comment_box:
            await comment_box.scroll_into_view_if_needed()
            await page.wait_for_timeout(random.randint(500, 1000))

            await comment_box.click()
            await page.wait_for_timeout(random.randint(300, 600))

            for char in comment_text:
                await comment_box.type(char)
                await asyncio.sleep(random.uniform(0.05, 0.15))
            await asyncio.sleep(60)
            await page.wait_for_timeout(random.randint(300, 800))

            # ĞŸĞ ĞĞ‘Ğ£Ğ„ĞœĞ Ğ·Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ "Ğ²Ñ–Ğ´Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚Ğ¸ ĞºĞ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€"
            # send_button = await page.query_selector('[data-e2e="post-comment"]')
            send_button = await page.query_selector('[data-e2e="comment-post"]')
            if send_button:
                await send_button.click()
                log.info("âœ… ĞšĞ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€ Ğ·Ğ°Ğ»Ğ¸ÑˆĞµĞ½Ğ¾.")
            else:
                log.warning("âŒ ĞšĞ½Ğ¾Ğ¿ĞºĞ° Ğ½Ğ°Ğ´ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ ĞºĞ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ñ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°.")
        else:
            log.warning("âŒ ĞŸĞ¾Ğ»Ğµ Ğ´Ğ»Ñ Ğ²Ğ²Ğ¾Ğ´Ñƒ ĞºĞ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ñ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
    except Exception as e:
        log.warning(f"âŒ ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ·Ğ°Ğ»Ğ¸ÑˆĞ¸Ñ‚Ğ¸ ĞºĞ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€: {e}")


async def get_video_links(page):
    await page.wait_for_selector('div[data-e2e="search_top-item-list"]', timeout=15000)
    videos = await page.query_selector_all('[data-e2e="search_top-item-list"] [data-e2e="search_top-item"]')
    links = []
    for video in videos:
        link_handle = await video.query_selector('a.css-1mdo0pl-AVideoContainer')
        href = await link_handle.get_attribute('href') if link_handle else None
        if href:
            links.append(href)
    log.info(f"Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ²Ñ–Ğ´ĞµĞ¾: {len(links)}")
    return links

async def watch_videos(page, video_links):
    for idx, href in enumerate(video_links):
        
        log.info(f"Ğ’Ñ–Ğ´ĞºÑ€Ğ¸Ğ²Ğ°Ñ”Ğ¼Ğ¾ Ğ²Ñ–Ğ´ĞµĞ¾ #{idx + 1}: {href}")
        await page.goto(href, wait_until="domcontentloaded", timeout=60000)
        
        watch_time = await get_video_duration(page)
        await asyncio.sleep(4)
        await check_captcha(page)

        html = await page.content()
        selector = Selector(text=html)
        data = selector.xpath("//script[@id='__UNIVERSAL_DATA_FOR_REHYDRATION__']/text()").get()
        data_for_parse = json.loads(data)["__DEFAULT_SCOPE__"]["webapp.video-detail"]["itemInfo"]["itemStruct"]
        data_to_save = await scrap_necessary_data(data_for_parse)
        print(data_to_save)
        await save_posts_to_csv([data_to_save])


        if should_execute_event(like_percent):  
                await like_video(page)

        if should_execute_event(comment_percent):  
                await leave_comment(page, "Ğ¥Ğ¼. Ğ¦Ñ–ĞºĞ°Ğ²Ğ¾...")

        if should_execute_event(skip_percent):
            await asyncio.sleep(4)
            await page.go_back()
            await page.wait_for_selector('div[data-e2e="search_top-item-list"]', timeout=10000)
        else:
            await asyncio.sleep(watch_time)


            # ĞŸĞ¾Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ğ¸ÑÑ Ğ½Ğ°Ğ·Ğ°Ğ´ Ğ½Ğ° ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ Ğ¿Ğ¾ÑˆÑƒĞºÑƒ
            await page.go_back()
            await page.wait_for_selector('div[data-e2e="search_top-item-list"]', timeout=10000)

async def scrape_search(context, keyword: str, max_results: int = 20):
    page = await context.new_page()
    
    search_url = f"https://www.tiktok.com/search?q={quote(keyword)}"
    log.info(f"Ğ’Ñ–Ğ´ĞºÑ€Ğ¸Ğ²Ğ°Ñ”Ğ¼Ğ¾ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ Ğ¿Ğ¾ÑˆÑƒĞºÑƒ: {search_url}")

    # await page.goto(search_url, wait_until="networkidle")
    await page.goto(search_url, wait_until="load")

    video_links = []
    while len(video_links) < max_results:
        new_links = await get_video_links(page)
        # Ğ”Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ ÑƒĞ½Ñ–ĞºĞ°Ğ»ÑŒĞ½Ñ– Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ
        for link in new_links:
            if link not in video_links:
                video_links.append(link)
                if len(video_links) >= max_results:
                    break
        if len(video_links) < max_results:
            log.info("ĞŸÑ€Ğ¾ĞºÑ€ÑƒÑ‡ÑƒÑ”Ğ¼Ğ¾ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºÑƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ½Ğ¾Ğ²Ğ¸Ñ… Ğ²Ñ–Ğ´ĞµĞ¾...")
            await page.evaluate("window.scrollBy(0, window.innerHeight)")
            await asyncio.sleep(3)

    await watch_videos(page, video_links[:max_results])

    return video_links[:max_results]

async def main():
    import sys
    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    playwright, context = await create_browser_with_session()

    keyword = "Ğ²Ğ¾Ğ´Ğ°"
    max_videos = 3
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ”Ğ¼Ğ¾ Ğ¿Ğ¾ÑˆÑƒĞº, Ğ¿ĞµÑ€ĞµĞ³Ğ»ÑĞ´ Ğ²Ñ–Ğ´ĞµĞ¾ Ñ– Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½ÑŒ
    try:
        video_links = await scrape_search(context, keyword, max_results=max_videos)
    finally:
        await context.close()
        # await browser.close()
        await playwright.stop()

    print("Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ– Ğ²Ñ–Ğ´ĞµĞ¾:")
    for link in video_links:
        print(link)

asyncio.run(main())